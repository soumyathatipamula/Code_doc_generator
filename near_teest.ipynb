{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sainithin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "c:\\Users\\sainithin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\utils\\hub.py:128: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\sainithin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from datasets import load_dataset\n",
    "from transformers import RobertaTokenizer, RobertaForCausalLM, Trainer, TrainingArguments\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"code_search_net\", \"python\",cache_dir=\"./Datasets\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train': ['repository_name',\n",
       "  'func_path_in_repository',\n",
       "  'func_name',\n",
       "  'whole_func_string',\n",
       "  'language',\n",
       "  'func_code_string',\n",
       "  'func_code_tokens',\n",
       "  'func_documentation_string',\n",
       "  'func_documentation_tokens',\n",
       "  'split_name',\n",
       "  'func_code_url'],\n",
       " 'test': ['repository_name',\n",
       "  'func_path_in_repository',\n",
       "  'func_name',\n",
       "  'whole_func_string',\n",
       "  'language',\n",
       "  'func_code_string',\n",
       "  'func_code_tokens',\n",
       "  'func_documentation_string',\n",
       "  'func_documentation_tokens',\n",
       "  'split_name',\n",
       "  'func_code_url'],\n",
       " 'validation': ['repository_name',\n",
       "  'func_path_in_repository',\n",
       "  'func_name',\n",
       "  'whole_func_string',\n",
       "  'language',\n",
       "  'func_code_string',\n",
       "  'func_code_tokens',\n",
       "  'func_documentation_string',\n",
       "  'func_documentation_tokens',\n",
       "  'split_name',\n",
       "  'func_code_url']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForCausalLM were not initialized from the model checkpoint at microsoft/codebert-base and are newly initialized: ['lm_head.bias', 'lm_head.decoder.bias', 'lm_head.dense.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\", cache_dir=\"./Models\")\n",
    "model = RobertaForCausalLM.from_pretrained(\"microsoft/codebert-base\", cache_dir=\"./Models\",is_decoder = True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_code(code_snippet, tokenizer):\n",
    "    return tokenizer(\n",
    "        code_snippet, max_length=512, truncation=True, padding='max_length', return_tensors=\"pt\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(batch, tokenizer):\n",
    "    batch[\"input_ids\"] = tokenize_code(batch[\"func_code_string\"], tokenizer)[\"input_ids\"]\n",
    "    batch[\"labels\"] = tokenize_code(batch[\"func_documentation_string\"], tokenizer)[\"input_ids\"]\n",
    "    return batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = dataset[\"train\"].shuffle(seed=42).select(range(1000)).map(lambda x: preprocess_data(x, tokenizer), batched=True)\n",
    "eval_dataset = dataset[\"validation\"].shuffle(seed=42).select(range(200)).map(lambda x: preprocess_data(x, tokenizer), batched=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RobertaForCausalLM(\n",
       "  (roberta): RobertaModel(\n",
       "    (embeddings): RobertaEmbeddings(\n",
       "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
       "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "      (token_type_embeddings): Embedding(1, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): RobertaEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x RobertaLayer(\n",
       "          (attention): RobertaAttention(\n",
       "            (self): RobertaSdpaSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): RobertaSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): RobertaIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): RobertaOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (lm_head): RobertaLMHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (layer_norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (decoder): Linear(in_features=768, out_features=50265, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sainithin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\training_args.py:1545: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./codebert-finetuned-roberta/results\",    # output directory\n",
    "    num_train_epochs=10,                   # number of epochs\n",
    "    per_device_train_batch_size=16,       # batch size\n",
    "    per_device_eval_batch_size=16,        # eval batch size\n",
    "    warmup_steps=500,                     # warmup steps\n",
    "    weight_decay=0.01,                    # weight decay\n",
    "    logging_dir=\"./logs\",                 # logging directory\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"steps\",          # Evaluation after every logging step\n",
    "    save_total_limit=2,                   # Keep only last two checkpoints\n",
    "    save_steps=500,                       # Save model every 500 steps\n",
    "    report_to=\"none\",\n",
    "    fp16=True                     # No reports (e.g., to wandb)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\sainithin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\accelerate\\accelerator.py:463: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n"
     ]
    }
   ],
   "source": [
    "# Trainer setup\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=eval_dataset,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/630 [00:00<?, ?it/s]We strongly recommend passing in an `attention_mask` since your input_ids may be padded. See https://huggingface.co/docs/transformers/troubleshooting#incorrect-output-when-padding-tokens-arent-masked.\n",
      "c:\\Users\\sainithin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\models\\roberta\\modeling_roberta.py:370: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:555.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n",
      "  2%|▏         | 10/630 [04:19<4:29:50, 26.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 18.2138, 'grad_norm': 63.97089767456055, 'learning_rate': 7.000000000000001e-07, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  2%|▏         | 10/630 [05:57<4:29:50, 26.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 18.06072998046875, 'eval_runtime': 98.6642, 'eval_samples_per_second': 2.027, 'eval_steps_per_second': 0.132, 'epoch': 0.16}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 20/630 [10:19<4:38:02, 27.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 17.815, 'grad_norm': 63.01264190673828, 'learning_rate': 1.7000000000000002e-06, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  3%|▎         | 20/630 [11:58<4:38:02, 27.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 17.291728973388672, 'eval_runtime': 98.5539, 'eval_samples_per_second': 2.029, 'eval_steps_per_second': 0.132, 'epoch': 0.32}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 30/630 [16:19<4:33:49, 27.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 16.7654, 'grad_norm': 57.824493408203125, 'learning_rate': 2.7e-06, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  5%|▍         | 30/630 [17:58<4:33:49, 27.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 15.921609878540039, 'eval_runtime': 98.5362, 'eval_samples_per_second': 2.03, 'eval_steps_per_second': 0.132, 'epoch': 0.48}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 40/630 [22:19<4:28:58, 27.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 15.2072, 'grad_norm': 55.265506744384766, 'learning_rate': 3.7e-06, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  6%|▋         | 40/630 [23:58<4:28:58, 27.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 14.1182222366333, 'eval_runtime': 98.4494, 'eval_samples_per_second': 2.032, 'eval_steps_per_second': 0.132, 'epoch': 0.63}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 50/630 [28:19<4:24:25, 27.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 13.214, 'grad_norm': 49.358726501464844, 'learning_rate': 4.7e-06, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      "  8%|▊         | 50/630 [29:57<4:24:25, 27.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 11.902570724487305, 'eval_runtime': 98.4252, 'eval_samples_per_second': 2.032, 'eval_steps_per_second': 0.132, 'epoch': 0.79}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 60/630 [34:19<4:19:51, 27.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 10.735, 'grad_norm': 42.13877868652344, 'learning_rate': 5.7000000000000005e-06, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 10%|▉         | 60/630 [35:57<4:19:51, 27.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 9.393935203552246, 'eval_runtime': 98.4339, 'eval_samples_per_second': 2.032, 'eval_steps_per_second': 0.132, 'epoch': 0.95}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 70/630 [40:06<4:12:22, 27.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 7.9519, 'grad_norm': 37.08514404296875, 'learning_rate': 6.700000000000001e-06, 'epoch': 1.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 11%|█         | 70/630 [41:44<4:12:22, 27.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 6.563320159912109, 'eval_runtime': 98.2585, 'eval_samples_per_second': 2.035, 'eval_steps_per_second': 0.132, 'epoch': 1.11}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 80/630 [46:05<4:10:15, 27.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.3564, 'grad_norm': 38.86039733886719, 'learning_rate': 7.7e-06, 'epoch': 1.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 13%|█▎        | 80/630 [47:43<4:10:15, 27.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.8364667892456055, 'eval_runtime': 98.2346, 'eval_samples_per_second': 2.036, 'eval_steps_per_second': 0.132, 'epoch': 1.27}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 90/630 [52:04<4:05:45, 27.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.0083, 'grad_norm': 15.443470001220703, 'learning_rate': 8.7e-06, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                  \n",
      " 14%|█▍        | 90/630 [53:42<4:05:45, 27.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.4120659828186035, 'eval_runtime': 98.2651, 'eval_samples_per_second': 2.035, 'eval_steps_per_second': 0.132, 'epoch': 1.43}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 100/630 [58:03<4:01:12, 27.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.7858, 'grad_norm': 5.62119197845459, 'learning_rate': 9.7e-06, 'epoch': 1.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                   \n",
      " 16%|█▌        | 100/630 [59:41<4:01:12, 27.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.1433205604553223, 'eval_runtime': 98.2443, 'eval_samples_per_second': 2.036, 'eval_steps_per_second': 0.132, 'epoch': 1.59}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 110/630 [1:04:02<3:56:43, 27.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.9412, 'grad_norm': 25.111492156982422, 'learning_rate': 1.0700000000000001e-05, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 17%|█▋        | 110/630 [1:05:40<3:56:43, 27.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 2.046808958053589, 'eval_runtime': 98.2786, 'eval_samples_per_second': 2.035, 'eval_steps_per_second': 0.132, 'epoch': 1.75}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 120/630 [1:10:01<3:52:08, 27.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6942, 'grad_norm': 4.7146711349487305, 'learning_rate': 1.1700000000000001e-05, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 19%|█▉        | 120/630 [1:11:39<3:52:08, 27.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9239897727966309, 'eval_runtime': 98.2528, 'eval_samples_per_second': 2.036, 'eval_steps_per_second': 0.132, 'epoch': 1.9}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 130/630 [1:15:47<3:39:34, 26.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6171, 'grad_norm': 35.03866195678711, 'learning_rate': 1.27e-05, 'epoch': 2.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 21%|██        | 130/630 [1:17:26<3:39:34, 26.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.890832543373108, 'eval_runtime': 98.3834, 'eval_samples_per_second': 2.033, 'eval_steps_per_second': 0.132, 'epoch': 2.06}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 140/630 [1:21:47<3:42:57, 27.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5519, 'grad_norm': 6.825279235839844, 'learning_rate': 1.3700000000000001e-05, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 22%|██▏       | 140/630 [1:23:25<3:42:57, 27.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.804990530014038, 'eval_runtime': 98.3702, 'eval_samples_per_second': 2.033, 'eval_steps_per_second': 0.132, 'epoch': 2.22}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 150/630 [1:27:46<3:38:38, 27.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6409, 'grad_norm': 7.955662250518799, 'learning_rate': 1.47e-05, 'epoch': 2.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 24%|██▍       | 150/630 [1:29:24<3:38:38, 27.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.9959540367126465, 'eval_runtime': 98.3894, 'eval_samples_per_second': 2.033, 'eval_steps_per_second': 0.132, 'epoch': 2.38}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 160/630 [1:33:46<3:34:05, 27.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.5351, 'grad_norm': 5.789573669433594, 'learning_rate': 1.5700000000000002e-05, 'epoch': 2.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 25%|██▌       | 160/630 [1:35:24<3:34:05, 27.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.8086962699890137, 'eval_runtime': 98.4175, 'eval_samples_per_second': 2.032, 'eval_steps_per_second': 0.132, 'epoch': 2.54}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 170/630 [1:39:45<3:29:29, 27.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3187, 'grad_norm': 5.638758659362793, 'learning_rate': 1.6700000000000003e-05, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 27%|██▋       | 170/630 [1:41:23<3:29:29, 27.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.7570443153381348, 'eval_runtime': 98.3937, 'eval_samples_per_second': 2.033, 'eval_steps_per_second': 0.132, 'epoch': 2.7}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▊       | 180/630 [1:45:50<3:32:10, 28.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2994, 'grad_norm': 3.6513569355010986, 'learning_rate': 1.77e-05, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 29%|██▊       | 180/630 [1:47:36<3:32:10, 28.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6654132604599, 'eval_runtime': 105.7219, 'eval_samples_per_second': 1.892, 'eval_steps_per_second': 0.123, 'epoch': 2.86}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 190/630 [1:51:53<3:07:29, 25.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2441, 'grad_norm': 7.131467342376709, 'learning_rate': 1.87e-05, 'epoch': 3.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 30%|███       | 190/630 [1:53:35<3:07:29, 25.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.6175390481948853, 'eval_runtime': 102.1133, 'eval_samples_per_second': 1.959, 'eval_steps_per_second': 0.127, 'epoch': 3.02}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 200/630 [1:58:06<3:22:33, 28.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2121, 'grad_norm': 3.989121675491333, 'learning_rate': 1.97e-05, 'epoch': 3.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 32%|███▏      | 200/630 [1:59:48<3:22:33, 28.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.649303913116455, 'eval_runtime': 102.0437, 'eval_samples_per_second': 1.96, 'eval_steps_per_second': 0.127, 'epoch': 3.17}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 210/630 [2:04:19<3:18:22, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.188, 'grad_norm': 2.066319465637207, 'learning_rate': 2.07e-05, 'epoch': 3.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 33%|███▎      | 210/630 [2:06:01<3:18:22, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5563119649887085, 'eval_runtime': 102.0351, 'eval_samples_per_second': 1.96, 'eval_steps_per_second': 0.127, 'epoch': 3.33}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 220/630 [2:10:32<3:13:39, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.4524, 'grad_norm': 5.586645126342773, 'learning_rate': 2.1700000000000002e-05, 'epoch': 3.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 35%|███▍      | 220/630 [2:12:14<3:13:39, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5339303016662598, 'eval_runtime': 102.0875, 'eval_samples_per_second': 1.959, 'eval_steps_per_second': 0.127, 'epoch': 3.49}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 230/630 [2:16:45<3:08:57, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0352, 'grad_norm': 2.45631742477417, 'learning_rate': 2.2700000000000003e-05, 'epoch': 3.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 37%|███▋      | 230/630 [2:18:27<3:08:57, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.523171067237854, 'eval_runtime': 102.0739, 'eval_samples_per_second': 1.959, 'eval_steps_per_second': 0.127, 'epoch': 3.65}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 240/630 [2:22:58<3:04:12, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9608, 'grad_norm': 4.037929534912109, 'learning_rate': 2.37e-05, 'epoch': 3.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 38%|███▊      | 240/630 [2:24:40<3:04:12, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5019946098327637, 'eval_runtime': 102.1641, 'eval_samples_per_second': 1.958, 'eval_steps_per_second': 0.127, 'epoch': 3.81}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 250/630 [2:29:11<2:59:29, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3032, 'grad_norm': 1.6020177602767944, 'learning_rate': 2.47e-05, 'epoch': 3.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 40%|███▉      | 250/630 [2:30:53<2:59:29, 28.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.5026812553405762, 'eval_runtime': 102.1276, 'eval_samples_per_second': 1.958, 'eval_steps_per_second': 0.127, 'epoch': 3.97}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████▏     | 260/630 [2:35:10<2:53:19, 28.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2494, 'grad_norm': 4.114760398864746, 'learning_rate': 2.57e-05, 'epoch': 4.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 41%|████▏     | 260/630 [2:36:54<2:53:19, 28.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.490681767463684, 'eval_runtime': 104.1022, 'eval_samples_per_second': 1.921, 'eval_steps_per_second': 0.125, 'epoch': 4.13}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 270/630 [2:41:29<2:51:01, 28.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0958, 'grad_norm': 1.419173002243042, 'learning_rate': 2.6700000000000002e-05, 'epoch': 4.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 43%|████▎     | 270/630 [2:43:11<2:51:01, 28.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4775652885437012, 'eval_runtime': 102.5612, 'eval_samples_per_second': 1.95, 'eval_steps_per_second': 0.127, 'epoch': 4.29}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 280/630 [2:47:42<2:45:29, 28.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0101, 'grad_norm': 3.212052822113037, 'learning_rate': 2.7700000000000002e-05, 'epoch': 4.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 44%|████▍     | 280/630 [2:49:24<2:45:29, 28.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4733206033706665, 'eval_runtime': 101.9181, 'eval_samples_per_second': 1.962, 'eval_steps_per_second': 0.128, 'epoch': 4.44}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 290/630 [2:53:55<2:40:53, 28.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2838, 'grad_norm': 1.561474323272705, 'learning_rate': 2.87e-05, 'epoch': 4.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 46%|████▌     | 290/630 [2:55:38<2:40:53, 28.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4769577980041504, 'eval_runtime': 102.2934, 'eval_samples_per_second': 1.955, 'eval_steps_per_second': 0.127, 'epoch': 4.6}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 300/630 [3:00:09<2:36:11, 28.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1144, 'grad_norm': 3.1627540588378906, 'learning_rate': 2.97e-05, 'epoch': 4.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 48%|████▊     | 300/630 [3:01:51<2:36:11, 28.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.447873830795288, 'eval_runtime': 102.3191, 'eval_samples_per_second': 1.955, 'eval_steps_per_second': 0.127, 'epoch': 4.76}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 310/630 [3:06:22<2:31:18, 28.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0621, 'grad_norm': 4.4483866691589355, 'learning_rate': 3.07e-05, 'epoch': 4.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 49%|████▉     | 310/630 [3:08:04<2:31:18, 28.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4556777477264404, 'eval_runtime': 102.147, 'eval_samples_per_second': 1.958, 'eval_steps_per_second': 0.127, 'epoch': 4.92}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 320/630 [3:12:22<2:23:15, 27.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0423, 'grad_norm': 3.4632248878479004, 'learning_rate': 3.1700000000000005e-05, 'epoch': 5.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 51%|█████     | 320/630 [3:14:04<2:23:15, 27.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4665087461471558, 'eval_runtime': 102.2118, 'eval_samples_per_second': 1.957, 'eval_steps_per_second': 0.127, 'epoch': 5.08}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 330/630 [3:18:35<2:21:34, 28.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1901, 'grad_norm': 3.2542998790740967, 'learning_rate': 3.27e-05, 'epoch': 5.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 52%|█████▏    | 330/630 [3:20:17<2:21:34, 28.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.445196270942688, 'eval_runtime': 102.269, 'eval_samples_per_second': 1.956, 'eval_steps_per_second': 0.127, 'epoch': 5.24}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 340/630 [3:24:48<2:17:13, 28.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9981, 'grad_norm': 2.506216049194336, 'learning_rate': 3.3700000000000006e-05, 'epoch': 5.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 54%|█████▍    | 340/630 [3:26:31<2:17:13, 28.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4267113208770752, 'eval_runtime': 102.3111, 'eval_samples_per_second': 1.955, 'eval_steps_per_second': 0.127, 'epoch': 5.4}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 350/630 [3:31:02<2:12:31, 28.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0915, 'grad_norm': 2.7236931324005127, 'learning_rate': 3.4699999999999996e-05, 'epoch': 5.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 56%|█████▌    | 350/630 [3:32:44<2:12:31, 28.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.471602201461792, 'eval_runtime': 102.2322, 'eval_samples_per_second': 1.956, 'eval_steps_per_second': 0.127, 'epoch': 5.56}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 360/630 [3:37:22<2:12:01, 29.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1306, 'grad_norm': 2.3553919792175293, 'learning_rate': 3.57e-05, 'epoch': 5.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 57%|█████▋    | 360/630 [3:39:07<2:12:01, 29.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.440331220626831, 'eval_runtime': 105.1871, 'eval_samples_per_second': 1.901, 'eval_steps_per_second': 0.124, 'epoch': 5.71}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▊    | 370/630 [3:43:48<2:07:31, 29.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0946, 'grad_norm': 2.5069327354431152, 'learning_rate': 3.6700000000000004e-05, 'epoch': 5.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 59%|█████▊    | 370/630 [3:45:34<2:07:31, 29.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.432854175567627, 'eval_runtime': 105.9194, 'eval_samples_per_second': 1.888, 'eval_steps_per_second': 0.123, 'epoch': 5.87}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 380/630 [3:49:59<1:53:22, 27.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0298, 'grad_norm': 2.4703848361968994, 'learning_rate': 3.77e-05, 'epoch': 6.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 60%|██████    | 380/630 [3:51:44<1:53:22, 27.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4182806015014648, 'eval_runtime': 104.8755, 'eval_samples_per_second': 1.907, 'eval_steps_per_second': 0.124, 'epoch': 6.03}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 390/630 [3:56:23<1:56:45, 29.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0224, 'grad_norm': 2.3515713214874268, 'learning_rate': 3.8700000000000006e-05, 'epoch': 6.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                     \n",
      " 62%|██████▏   | 390/630 [3:58:09<1:56:45, 29.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 1.4271224737167358, 'eval_runtime': 105.7196, 'eval_samples_per_second': 1.892, 'eval_steps_per_second': 0.123, 'epoch': 6.19}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 391/630 [3:58:37<4:01:28, 60.62s/it]"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./codebert-finetuned-roberta\")\n",
    "tokenizer.save_pretrained(\"./codebert-finetuned-roberta\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_documentation(code_snippet, model, tokenizer):\n",
    "    # Tokenize input\n",
    "    inputs = tokenizer(code_snippet, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n",
    "    \n",
    "    # Generate output\n",
    "    outputs = model.generate(inputs[\"input_ids\"], max_length=150, num_beams=5, early_stopping=True)\n",
    "    \n",
    "    # Decode generated text\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "code_example = \"\"\"\n",
    "def add_numbers(a, b):\n",
    "    return a + c\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "documentation = generate_documentation(code_example, model, tokenizer)\n",
    "print(\"Generated Documentation:\", documentation)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
